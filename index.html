<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Academic Homepage of Yang Liu">
    <meta name="author" content="Yang Liu">
    <title>Yang Liu (刘阳) @ SYSU</title>

    <!-- Bootstrap 5 CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- FontAwesome Icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <!-- Academicons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&family=Saira+Extra+Condensed:wght@500;700&display=swap" rel="stylesheet">

    <style>
        body {
            font-family: 'Roboto', sans-serif;
            color: #343a40;
            padding-top: 56px; /* 移动端顶部导航高度占位 */
        }

        a {
            color: #bd5d38;
            text-decoration: none;
            transition: color 0.3s;
        }

        a:hover {
            color: #884429;
            text-decoration: underline;
        }

        /* --------------------------------------------------
           桌面端侧边栏核心布局 (大屏幕)
        -------------------------------------------------- */
        @media (min-width: 992px) {
            body {
                padding-top: 0;
                padding-left: 17rem; /* 给右侧内容预留空间 */
            }

            .navbar {
                position: fixed;
                top: 0;
                left: 0;
                display: flex;
                flex-direction: column; /* 导航栏整体纵向 */
                width: 17rem; /* 固定宽度 */
                height: 100vh;
                background-color: #bd5d38; 
                text-align: center;
                overflow-y: auto; /* 防止屏幕过矮时内容被截断 */
            }

            .navbar .container-fluid {
                display: flex;
                flex-direction: column; /* 容器内部纵向 */
                padding: 0;
                height: 100%;
            }

            .navbar .navbar-brand {
                margin: 0;
                padding: 2rem 0 1rem 0;
                display: flex;
                justify-content: center;
            }

            .navbar .navbar-brand .img-profile {
                /* 大头像设置 */
                width: 10rem;
                height: 10rem;
                max-width: 10rem;
                max-height: 10rem;
                border: 0.5rem solid rgba(255, 255, 255, 0.2);
                border-radius: 50%;
                object-fit: cover;
                transition: transform 0.3s;
            }
            
            .navbar .navbar-brand .img-profile:hover {
                transform: scale(1.05);
            }

            /* 强制覆盖 Bootstrap 的横向排列，确保菜单项垂直 */
            .navbar-collapse {
                display: flex !important;
                flex-direction: column !important; 
                flex-grow: 1; /* 让菜单占据剩余空间 */
                align-items: center;
                width: 100%;
            }

            .navbar-nav {
                flex-direction: column !important; /* 核心：强制纵向 */
                width: 100%;
                margin-bottom: auto; /* 顶对齐 */
            }

            .nav-item {
                width: 100%;
                display: block;
            }

            .nav-link {
                display: block;
                text-align: center;
                text-transform: uppercase;
                font-weight: 700;
                letter-spacing: 0.05rem;
                padding: 1rem 0; /* 增加点击区域高度 */
                color: rgba(255, 255, 255, 0.8) !important;
                font-size: 1.1rem; /* 字体大小 */
                white-space: normal; /* 允许文字换行，防止超出 */
            }
            
            .nav-link:hover, .nav-link.active {
                color: #fff !important;
                background-color: rgba(0,0,0,0.1);
            }

            /* 右侧内容区域内边距 */
            section.resume-section {
                padding-left: 3rem !important; 
                padding-right: 3rem !important;
            }
        }

        /* --------------------------------------------------
           移动端样式 (小屏幕)
        -------------------------------------------------- */
        @media (max-width: 991.98px) {
            .navbar {
                background-color: #bd5d38; 
            }
            .img-profile {
                max-width: 3rem;
                border: 2px solid rgba(255,255,255,0.2);
            }
        }

        /* --------------------------------------------------
           通用板块样式
        -------------------------------------------------- */
        section.resume-section {
            padding-top: 3rem !important;
            padding-bottom: 3rem !important;
            padding-left: 1.5rem;  
            padding-right: 1.5rem;
            border-bottom: 1px solid #dee2e6;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        h1, h2, h3 {
            font-family: 'Saira Extra Condensed', serif;
            font-weight: 700;
            text-transform: uppercase;
            color: #343a40;
        }

        h2 { font-size: 3.5rem; line-height: 3.5rem; }
        h3 { font-size: 2rem; margin-bottom: 1.5rem; color: #575d63;}

        .subheading {
            font-family: 'Saira Extra Condensed', serif;
            text-transform: uppercase;
            font-weight: 500;
            font-size: 1.35rem;
            color: #bd5d38;
        }

        /* News Box */
        .news-box {
            max-height: 400px;
            overflow-y: auto;
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            border-left: 5px solid #bd5d38;
        }
        .news-box ul { padding-left: 1.2rem; }
        .news-box li { margin-bottom: 8px; font-size: 0.95rem; }

        /* Publication Cards */
        .pub-card {
            border: none;
            margin-bottom: 2rem;
            background: transparent;
        }
        .pub-img-container {
            overflow: hidden;
            border-radius: 6px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .pub-img {
            width: 100%;
            height: auto;
            object-fit: cover;
            transition: transform 0.3s;
        }
        .pub-card:hover .pub-img {
            transform: scale(1.03);
        }
        .pub-title {
            font-weight: 700;
            font-size: 1.15rem;
            color: #212529;
        }
        .pub-authors {
            color: #6c757d;
            font-size: 0.95rem;
            margin-bottom: 0.25rem;
        }
        .pub-venue {
            font-style: italic;
            color: #343a40;
            font-weight: 500;
        }
        .badge-custom {
            background-color: #bd5d38; 
            font-weight: normal;
        }
        .badge-hot {
            background-color: #dc3545;
        }
        
        /* Links & Buttons */
        .pub-links a {
            font-size: 0.85rem;
            margin-right: 10px;
            color: #495057;
            text-decoration: none;
            border: 1px solid #dee2e6;
            padding: 2px 8px;
            border-radius: 4px;
            background: #fff;
            transition: all 0.2s;
            display: inline-block;
            margin-bottom: 5px;
        }
        .pub-links a:hover {
            background: #e9ecef;
            border-color: #adb5bd;
            color: #000;
        }
        
        /* Github Badges container */
        .github-badges {
            margin-top: 5px;
        }
        .github-badges img {
            height: 20px;
            margin-right: 5px;
        }

        /* Bibtex Block */
        .bibtex-box {
            background-color: #f1f3f5;
            padding: 10px;
            border-radius: 5px;
            font-size: 0.8rem;
            margin-top: 10px;
            font-family: monospace;
            border: 1px solid #ddd;
        }

        /* Social Icons */
        .social-icons a {
            display: inline-block;
            height: 3.5rem;
            width: 3.5rem;
            background-color: #495057;
            color: #fff !important;
            border-radius: 100%;
            text-align: center;
            font-size: 1.5rem;
            line-height: 3.5rem;
            margin-right: 1rem;
            transition: background 0.3s;
        }
        .social-icons a:hover {
            background-color: #bd5d38;
        }
    </style>
</head>

<body id="page-top" data-bs-spy="scroll" data-bs-target="#sideNav" data-bs-offset="0" tabindex="0">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="sideNav">
        <div class="container-fluid">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Yang Liu</span>
                <span class="d-none d-lg-block">
                    <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="./img/YangLiu_2025.jpg" alt="Yang Liu Profile">
                </span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">Introduction</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#news">News</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#activities">Activities</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <div class="container-fluid p-0">

        <!-- About Section -->
        <section class="resume-section" id="about">
            <div class="resume-section-content">
                <h1 class="mb-0">Yang <span class="text-primary" style="color: #bd5d38 !important;">Liu</span> (刘阳)</h1>
                <div class="subheading mb-4">
                    Associate Professor @ Sun Yat-sen University
                </div>
                
                <div class="row mb-5">
                    <div class="col-lg-8">
                        <p class="lead mb-4">
                            IEEE/ACM Member, CCF/CAAI/CSIG Member<br>
                            <i class="fas fa-envelope me-2"></i>Email: liuy856@mail.sysu.edu.cn<br>
                            <i class="fas fa-map-marker-alt me-2"></i>Office: School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China
                        </p>
                        <p>
                            I am currently an associate professor at <a href="http://www.sysu-hcp.net/" target="_blank">HCP Lab</a>, <a href="http://sdcs.sysu.edu.cn/" target="_blank">School of Computer Science and Engineering</a>, <a href="http://www.sysu.edu.cn/" target="_blank">Sun Yat-sen University</a>. 
                            Previously, I worked as a research fellow with <a href="http://www.linliang.net/" target="_blank">Prof. Liang Lin</a>. 
                            I obtained my Ph.D. degree from Xidian University in 2019. 
                            <a href="https://cse.sysu.edu.cn/teacher/LiuYang" target="_blank">[中文版]</a>
                        </p>
                        <div class="alert alert-warning border-start border-warning border-4" role="alert">
                            <strong>Recruiting:</strong> Looking for self-motivated Masters, RAs, visiting students, and interns. Please drop me an email if interested.
                        </div>
                    </div>
                    <div class="col-lg-4 text-center">
                        <!-- Visitor Map -->
                        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=m&d=Ng_LP0UrQP5gWGJEym9UVNi8Up0eZ-cQXq9wH1Me7Bg"></script>
                    </div>
                </div>

                <h3 class="mb-3">Research Interests</h3>
                <ul class="list-group list-group-flush mb-4">
                    <li class="list-group-item bg-transparent"><i class="fas fa-robot text-warning me-2"></i> <strong>Embodied AI:</strong> Embodied Interaction, Embodied Manipulation, Robotic Control</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-eye text-primary me-2"></i> <strong>Computer Vision:</strong> Cross-modal Reasoning, Spatial-temporal Representation Learning</li>
                    <li class="list-group-item bg-transparent"><i class="fas fa-brain text-success me-2"></i> <strong>Machine Learning:</strong> Causal Inference, Self-supervised Learning, Transfer Learning</li>
                </ul>

                <h3 class="mb-3">Selected Awards</h3>
                <div class="row">
                    <div class="col-md-12">
                         <ul class="fa-ul mb-0">
                            <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>Excellent Author of Publishing House of Electronics Industry (PHE), 2024.</li>
                            <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>CCF ChinaSoft 2023 Robotic Big Model and Embodied Intelligence Challenge, Third Prize, 2023.</li>
                            <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>The Third Guangdong Province Young Computer Science Academic Show, First Prize, 2023.</li>
                            <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>National Scholarship for PhD Students, 2018.</li>
                        </ul>
                    </div>
                </div>

                <div class="social-icons mt-5">
                    <a href="https://scholar.google.com/citations?user=l0z2QNQAAAAJ&hl=en" target="_blank" title="Google Scholar">
                        <i class="ai ai-google-scholar"></i>
                    </a>
                    <a href="https://github.com/YangLiu9208" target="_blank" title="GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                    <a href="https://dblp.uni-trier.de/pid/51/3710-84.html" target="_blank" title="DBLP">
                        <i class="ai ai-dblp"></i>
                    </a>
                    <a href="https://www.researchgate.net/profile/Yang-Liu-30" target="_blank" title="ResearchGate">
                        <i class="ai ai-researchgate"></i>
                    </a>
                </div>
            </div>
        </section>

        <hr class="m-0">

        <!-- News Section -->
        <section class="resume-section" id="news">
            <div class="resume-section-content">
                <h2 class="mb-5">News</h2>
                <div class="news-box">
                    <ul class="list-unstyled">
                        <li><strong>2025-11:</strong> One T-IP paper is selected as the ESI Highly Cited Paper!</li>
                        <li><strong>2025-09:</strong> Two papers are accepted by NeurIPS 2025!</li>
                        <li><strong>2025-08:</strong> One paper is accepted by Neural Networks!</li>
                        <li><strong>2025-07:</strong> One paper is accepted by ACM MM 2025 as <span class="badge bg-danger">Oral</span>!</li>
                        <li><strong>2025-06:</strong> One paper is accepted by ICCV 2025!</li>
                        <li><strong>2025-06:</strong> One paper is accepted by IEEE Transactions on Knowledge and Data Engineering!</li>
                        <li><strong>2025-05:</strong> Our Embodied AI Survey paper is accepted by IEEE/ASME Transactions on Mechatronics!</li>
                        <li><strong>2025-05:</strong> One paper is accepted by ACL 2025!</li>
                        <li><strong>2025-05:</strong> One paper Cross-Modal Causal Representation Learning for Radiology Report Generation is accepted by IEEE T-IP!</li>
                        <li><strong>2025-04:</strong> Our CRA-GQA is selected as CVPR 2025 <span class="badge bg-warning text-dark">Highlight</span>!</li>
                        <li><strong>2025-02:</strong> Three papers are accepted by CVPR 2025!</li>
                        <li><strong>2024-07:</strong> We release the <a href="https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List" target="_blank">paper list</a> for Embodied AI!</li>
                        <li><strong>2024-07:</strong> One paper is accepted by ACM MM 2024!</li>
                        <li><strong>2024-06:</strong> The book <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank">《多模态大模型：新一代人工智能技术范式》</a> is selected for the SYSU Undergraduate Textbook Series!</li>
                        <li><strong>2024-05:</strong> One first-author T-PAMI paper is selected as the ESI Hot Cited Paper!</li>
                        <li><strong>2024-05:</strong> One first-author T-PAMI paper is selected as the ESI Highly Cited Paper!</li>
                        <li><strong>2024-04:</strong> The book of multimodal large model <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank">《多模态大模型：新一代人工智能技术范式》</a> is published!</li>
                        <li><strong>2023-12:</strong> I won the third prize of CCF ChinaSoft 2023 Robotic Big Model and Embodied Intelligence Challenge!</li>
                        <li><strong>2023-11:</strong> One first-author T-IP paper is selected as the ESI Hot Cited Paper!</li>
                        <li><strong>2023-10:</strong> An invention patent has been granted.</li>
                        <li><strong>2023-07:</strong> One paper accepted by ACM MM 2023!</li>
                        <li><strong>2023-07:</strong> Two papers accepted by ICCV 2023!</li>
                        <li><strong>2023-06:</strong> One paper accepted by T-PAMI!</li>
                        <li><strong>2023-03:</strong> The open-source framework <a href="https://github.com/YangLiu9208/Causal-VLReasoning" target="_blank">Causal-VLReasoning</a> is online!</li>
                        <li><strong>2022-03:</strong> One paper accepted by CVPR 2022 as oral presentation.</li>
                        <li><strong>2021-10:</strong> I start working as a research associate professor at Sun-Yat-Sen University.</li>
                    </ul>
                </div>
            </div>
        </section>

        <hr class="m-0">

        <!-- Publications Section -->
        <section class="resume-section" id="publications">
            <div class="resume-section-content">
                <h2 class="mb-5">Publications</h2>

                <!-- Books -->
                <h3 class="mb-4">Books</h3>
                
                <!-- Book 1 -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3 text-center">
                            <div class="pub-img-container">
                                <img src="img/PHE.jpg" class="pub-img" alt="Book Cover">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Multimodal Large Models: The New Paradigm of Artificial General Intelligence</h5>
                                <h6 class="card-subtitle mb-2 text-muted">《多模态大模型：新一代人工智能技术范式》</h6>
                                <p class="pub-authors"><b>Yang Liu</b>, Liang Lin</p>
                                <p class="pub-venue">Publishing House of Electronics Industry (PHE), 2024. <span class="badge bg-success">Textbook Series</span></p>
                                <div class="pub-links">
                                    <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank"><i class="fas fa-globe"></i> Resource Page</a>
                                    <a href="https://item.jd.com/10100489294930.html" target="_blank"><i class="fas fa-shopping-cart"></i> JD.com</a>
                                    <a href="https://mp.weixin.qq.com/s/WHYy-dlJl6V4TQoZxWIiYQ" target="_blank"><i class="fab fa-weixin"></i> Media</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/Book-of-MLM">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/Book-of-MLM">
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Book 2 -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3 text-center">
                            <div class="pub-img-container">
                                <img src="img/PHE-ENG.png" class="pub-img" alt="Book Cover">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Multimodal Large Models: The New Paradigm of Artificial Intelligence</h5>
                                <p class="pub-authors">Liang Lin, <b>Yang Liu</b></p>
                                <p class="pub-venue">Springer, 2025.</p>
                                <div class="pub-links">
                                    <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank"><i class="fas fa-globe"></i> Resource Page</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/Book-of-MLM">
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Open Source Framework -->
                <h3 class="mb-4 mt-5">Open-source Framework</h3>
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3 text-center">
                            <div class="pub-img-container">
                                <img src="img/CausalVLR.gif" class="pub-img" alt="Framework Demo">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">CausalVLR: A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Weixing Chen, Guanbin Li, Liang Lin</p>
                                <p class="card-text text-muted small">CausalVLR is a python open-source framework for causal relation discovery and inference, implementing SOTA causality learning algorithms for various visual-linguistic reasoning tasks.</p>
                                <div class="pub-links">
                                    <a href="https://github.com/HCPLab-SYSU/CausalVLR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="https://arxiv.org/pdf/2306.17462.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibCausal" data-bs-toggle="collapse" role="button" aria-expanded="false"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CausalVLR">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/CausalVLR">
                                </div>
                                <div class="collapse bibtex-box" id="bibCausal">
@article{CausalVLR,
  title={CausalVLR: A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning},
  author={Liu, Yang and Chen, Weixing and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2306.17462},
  year={2023}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Papers List -->
                <h3 class="mb-4 mt-5">Selected Papers</h3>

                <!-- Paper: 3DAffordSplat -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/3DAffordSplat.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians</h5>
                                <p class="pub-authors">Zeming Wei#, Junyi Lin#, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">ACM International Conference on Multimedia (ACM MM), 2025 <span class="badge badge-hot">Oral</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2504.11218" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/3DAffordSplat/" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bib3DAffordSplat" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/3DAffordSplat">
                                </div>
                                <div class="collapse bibtex-box" id="bib3DAffordSplat">
@article{3DAffordSplat,
  title={3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians},
  author={Wei, Zeming and Lin, Junyi and Liu, Yang and Chen, Weixing and Luo, Jingzhou and Li, Guanbin and Lin, Liang},
  year={2025},
  journal={arXiv preprint arXiv:2504.11218}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: EXPRESS-Bench -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/EXPRESS-Bench.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering</h5>
                                <p class="pub-authors">Kaixuan Jiang, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Jingzhou Luo, Ziliang Chen, Ling Pan, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2503.11117" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/EXPRESS-Bench/" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibEXPRESS" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/EXPRESS-Bench">
                                </div>
                                <div class="collapse bibtex-box" id="bibEXPRESS">
@inproceedings{EXPRESSBench,
  title={Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering},
  author={Jiang, Kaixuan and Liu, Yang and Chen, Weixing and Luo, Jingzhou and Chen, Ziliang and Pan, Ling and Li, Guanbin and Lin, Liang},
  year={2025},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: Embodied Survey -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/Embodied_survey.jpg" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Weixing Chen, Yongjie Bai, Xiaodan Liang, Guanbin Li, Wen Gao, Liang Lin</p>
                                <p class="pub-venue">IEEE/ASME Transactions on Mechatronics, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2407.06886" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List" target="_blank"><i class="fab fa-github"></i> Paper List</a>
                                    <a href="#bibEmbodiedSurvey" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/Embodied_AI_Paper_List">
                                </div>
                                <div class="collapse bibtex-box" id="bibEmbodiedSurvey">
@article{liu2024aligning,
  title={Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI},
  author={Liu, Yang and Chen, Weixing and Bai, Yongjie and Liang, Xiaodan and Li, Guanbin and Gao, Wen and Lin, Liang},
  journal={arXiv preprint arXiv:2407.06886},
  year={2024}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: VLCI -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/VLCI.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-Modal Causal Representation Learning for Radiology Report Generation</h5>
                                <p class="pub-authors">Weixing Chen, <b>Yang Liu</b><sup>✉</sup>, Ce Wang, Jiarui Zhu, Guanbin Li, Cheng-Lin Liu, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2025 <span class="badge badge-hot">ESI Highly Cited</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2303.09117" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/WissingChen/VLCI" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibVLCI" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/WissingChen/VLCI">
                                </div>
                                <div class="collapse bibtex-box" id="bibVLCI">
@article{chen2025visual,
  title={Cross-Modal Causal Representation Learning for Radiology Report Generation},
  author={Chen, Weixing and Liu, Yang and Wang, Ce and Zhu, Jiarui and Li, Guanbin and Liu, Cheng-Lin and Lin, Liang},
  journal={IEEE Transactions on Image Processing},
  year={2025}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: ODMixer -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/ODMixer.jpg" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">ODMixer: Fine-grained Spatial-temporal MLP for Metro Origin-Destination Prediction</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Binglin Chen, Yongsen Zheng, Lechao Cheng, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Knowledge and Data Engineering (TKDE), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2404.15734" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/KLatitude/ODMixer" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibODMixer" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/KLatitude/ODMixer">
                                </div>
                                <div class="collapse bibtex-box" id="bibODMixer">
@article{liu2024fine,
  title={ODMixer: Fine-grained Spatial-temporal MLP for Metro Origin-Destination Prediction},
  author={Liu, Yang and Chen, Binglin and Zheng, Yongsen and Cheng, Lechao and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2404.15734},
  year={2024}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: TAVP -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/TAVP.jpg" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Learning to See and Act: Task-Aware View Planning for Robotic Manipulation</h5>
                                <p class="pub-authors">Yongjie Bai#, Zhouxia Wang#, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Preprint, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2508.05186" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/TAVP/" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibTAVP" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/TAVP">
                                </div>
                                <div class="collapse bibtex-box" id="bibTAVP">
@misc{bai2025learningacttaskawareview,
  title={Learning to See and Act: Task-Aware View Planning for Robotic Manipulation}, 
  author={Yongjie Bai and Zhouxia Wang and Yang Liu and Weixing Chen and Ziliang Chen and Mingtong Dai and Yongsen Zheng and Lingbo Liu and Guanbin Li and Liang Lin},
  year={2025},
  eprint={2508.05186},
  archivePrefix={arXiv},
  primaryClass={cs.RO}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: AutoLayout -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/AutoLayout.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning</h5>
                                <p class="pub-authors">Weixing Chen, Dafeng Chi, <b>Yang Liu</b><sup>✉</sup>, Yuxi Yang, Yexin Zhang, Yuzheng Zhuang, Xingyue Quan, Jianye Hao, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Preprint, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2507.04293" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibAutoLayout" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibAutoLayout">
@article{chen2025autolayout,
  title={AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning},
  author={Chen, Weixing and Chi, Dafeng and Liu, Yang and Yang, Yuxi and Zhang, Yexin and Zhuang, Yuzheng and Quan, Xingyue and Hao, Jianye and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2507.04293},
  year={2025}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DART -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/DART.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Foundation Models</h5>
                                <p class="pub-authors">Shicheng Yin, Kaixuan Yin, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Liang Lin</p>
                                <p class="pub-venue">Preprint, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2506.10390" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/DART" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibDART" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/DART">
                                </div>
                                <div class="collapse bibtex-box" id="bibDART">
@article{yin2025dart,
  title={DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba},
  author={Shicheng Yin and Kaixuan Yin and Yang Liu and Weixing Chen and Liang Lin},
  journal={arXiv preprint arXiv:2506.10390},
  year={2025}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: LHPR-VLN -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/LHPR-VLN.gif" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method</h5>
                                <p class="pub-authors">Xinshuai Song*, Weixing Chen*, <b>Yang Liu</b><sup>✉</sup>, Weikai Chen, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2412.09082" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/LH-VLN" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibLHVLN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/LH-VLN">
                                </div>
                                <div class="collapse bibtex-box" id="bibLHVLN">
@inproceedings{song2024towards,
  title={Towards long-horizon vision-language navigation: Platform, benchmark and method},
  author={Song, Xinshuai and Chen, Weixing and Liu, Yang and Chen, Weikai and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DSPNet -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/DSPNet.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering</h5>
                                <p class="pub-authors">Jingzhou Luo, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Zhen Li, Yaowei Wang, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2503.03190" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/LZ-CH/DSPNet" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibDSPNet" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/LZ-CH/DSPNet">
                                </div>
                                <div class="collapse bibtex-box" id="bibDSPNet">
@inproceedings{luo2025dspnet,
  title={DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering},
  author={Luo, Jingzhou and Liu, Yang and Chen, Weixing and Li, Zhen and Wang, Yaowei and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CRA-GQA -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/CRA.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-modal Causal Relation Alignment for Video Question Grounding</h5>
                                <p class="pub-authors">Weixing Chen, <b>Yang Liu</b><sup>✉</sup>, Binglin Chen, Jiandong Su, Yongsen Zheng, Liang Lin</p>
                                <p class="pub-venue">CVPR 2025 <span class="badge badge-hot">Highlight</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2503.07635" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/WissingChen/CRA-GQA" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibCRA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/WissingChen/CRA-GQA">
                                </div>
                                <div class="collapse bibtex-box" id="bibCRA">
@inproceedings{chen2025cross,
  title={Cross-modal Causal Relation Alignment for Video Question Grounding},
  author={Chen, Weixing and Liu, Yang and Chen, Binglin and Su, Jiandong and Zheng, Yongsen and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: InfiniteWorld -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/InfiniteWorld.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">InfiniteWorld: A Unified Scalable Simulation Framework for General Visual-Language Robot Interaction</h5>
                                <p class="pub-authors">Pengzhen Ren, Min Li, Zhen Luo, Xinshuai Song, Ziwei Chen, Weijia Liufu, Yixuan Yang, Hao Zheng, Rongtao Xu, Zitong Huang, Tongsheng Ding, Luyang Xie, Kaidong Zhang, Changfei Fu, <b>Yang Liu</b>, Liang Lin, Feng Zheng, Xiaodan Liang</p>
                                <p class="pub-venue">arXiv:2412.05789</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2412.05789" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/pzhren/InfiniteWorld" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibInfiniteWorld" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/pzhren/InfiniteWorld">
                                </div>
                                <div class="collapse bibtex-box" id="bibInfiniteWorld">
@article{ren2024infiniteworld,
  title={InfiniteWorld: A Unified Scalable Simulation Framework for General Visual-Language Robot Interaction},
  author={Ren, Pengzhen and Li, Min and Luo, Zhen and Song, Xinshuai and Chen, Ziwei and Liufu, Weijia and Yang, Yixuan and Zheng, Hao and Xu, Rongtao and Huang, Zitong and others},
  journal={arXiv preprint arXiv:2412.05789},
  year={2024}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CMCIR -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/VLCIR.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2023 <span class="badge badge-hot">ESI Highly Cited & Hot Paper</span></p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/10146482" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/CMCIR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibCMCIR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CMCIR">
                                </div>
                                <div class="collapse bibtex-box" id="bibCMCIR">
@article{liu2022cross,
  author={Liu, Yang and Li, Guanbin and Lin, Liang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering}, 
  year={2023},
  doi={10.1109/TPAMI.2023.3284038}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CRS -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/CRS.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Diversity Matters: User-Centric Multi-Interest Learning for Conversational Movie Recommendation</h5>
                                <p class="pub-authors">Yongsen Zheng, Guohua Wang, <b>Yang Liu</b>, Liang Lin</p>
                                <p class="pub-venue">ACM International Conference on Multimedia (ACM MM), 2024</p>
                                <div class="pub-links">
                                    <a href="https://yangliu9208.github.io/" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: MEIA -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/MEIA.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">MEIA: Multimodal Embodied Perception and Interaction in Unknown Environments</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Xinshuai Song, Kaixuan Jiang, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">arXiv:2402.00290</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2402.00290v2" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibMEIA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibMEIA">
@article{liu2024multimodal,
  title={MEIA: Multimodal Embodied Perception and Interaction in Unknown Environments},
  author={Liu, Yang and Song, Xinshuai and Jiang, Kaixuan and Chen, Weixing and Luo, Jingzhou and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2402.00290},
  year={2024}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CausalGPT -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/CaCoCoT.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">CausalGPT: Illuminating Faithfulness and Causality for Knowledge-based Reasoning with LLMs</h5>
                                <p class="pub-authors">Ziyi Tang, Ruilin Wang, Weixing Chen, Yongsen Zheng, <b>Yang Liu</b>, Keze Wang, Tianshui Chen, Liang Lin</p>
                                <p class="pub-venue">arXiv:2308.11914</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2308.11914.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/CausalVLR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibCausalGPT" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CausalVLR">
                                </div>
                                <div class="collapse bibtex-box" id="bibCausalGPT">
@article{tang2023towards,
  title={Towards causalgpt: A multi-agent approach for faithful knowledge reasoning via promoting causal consistency in llms},
  author={Tang, Ziyi and Wang, Ruilin and Chen, Weixing and Wang, Keze and Liu, Yang and Chen, Tianshui and Lin, Liang},
  journal={arXiv preprint arXiv:2308.11914},
  year={2023}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: VCSR -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/VCSR.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Visual Causal Scene Refinement for Video Question Answering</h5>
                                <p class="pub-authors">Yushen Wei*, <b>Yang Liu*</b>, Hong Yan, Guanbin Li, Liang Lin<sup>✉</sup></p>
                                <p class="pub-venue">ACM MM 2023 <span class="badge badge-hot">Oral</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2305.04224.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/CausalVLR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibVCSR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CausalVLR">
                                </div>
                                <div class="collapse bibtex-box" id="bibVCSR">
@inproceedings{10.1145/3581783.3611873,
  author = {Wei, Yushen and Liu, Yang and Yan, Hong and Li, Guanbin and Lin, Liang},
  title = {Visual Causal Scene Refinement for Video Question Answering},
  year = {2023},
  series = {MM '23}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: SkeletonMAE -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/SkeletonMAE.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">SkeletonMAE: Graph-based Masked Autoencoder for Skeleton Sequence Pre-training</h5>
                                <p class="pub-authors">Hong Yan, <b>Yang Liu</b><sup>✉</sup>, Yushen Wei, Zhen Li, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2023</p>
                                <div class="pub-links">
                                    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HongYan1123/SkeletonMAE" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibSkeletonMAE" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HongYan1123/SkeletonMAE">
                                </div>
                                <div class="collapse bibtex-box" id="bibSkeletonMAE">
@inproceedings{yan2023skeletonmae,
  title={Skeletonmae: graph-based masked autoencoder for skeleton sequence pre-training},
  author={Yan, Hong and Liu, Yang and Wei, Yushen and Li, Zhen and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: ESL -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/ESL.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Enhanced Soft Label for Semi-Supervised Semantic Segmentation</h5>
                                <p class="pub-authors">Jie Ma, Chuan Wang, <b>Yang Liu</b>, Liang Lin, Guanbin Li</p>
                                <p class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2023</p>
                                <div class="pub-links">
                                    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/unrealMJ/ESL" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibESL" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/unrealMJ/ESL">
                                </div>
                                <div class="collapse bibtex-box" id="bibESL">
@inproceedings{ma2023enhanced,
  title={Enhanced Soft Label for Semi-Supervised Semantic Segmentation},
  author={Ma, Jie and Wang, Chuan and Liu, Yang and Lin, Liang and Li, Guanbin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DenseLight -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/DenseLight.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">DenseLight: Efficient Control for Large-scale Traffic Signals with Dense Feedback</h5>
                                <p class="pub-authors">Junfan Lin, Yuying Zhu, Lingbo Liu, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IJCAI 2023</p>
                                <div class="pub-links">
                                    <a href="https://yangliu9208.github.io/home/" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/junfanlin/DenseLight" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibDenseLight" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/junfanlin/DenseLight">
                                </div>
                                <div class="collapse bibtex-box" id="bibDenseLight">
@inproceedings{ijcai2023p672,
  title={DenseLight: Efficient Control for Large-scale Traffic Signals with Dense Feedback},
  author={Lin, Junfan and Zhu, Yuying and Liu, Lingbo and Liu, Yang and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, {IJCAI-23}},
  year={2023}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: HORLN -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/HORLN.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Hybrid-Order Representation Learning for Electricity Theft Detection</h5>
                                <p class="pub-authors">Yuying Zhu, Yang Zhang, Lingbo Liu, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Mingzhi Mao, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Industrial Informatics (T-II), 2023</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/9785914" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/GillianZhu/HORLN" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibHORLN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/GillianZhu/HORLN">
                                </div>
                                <div class="collapse bibtex-box" id="bibHORLN">
@article{zhu2022hybrid,
  title={Hybrid-Order Representation Learning for Electricity Theft Detection},
  author={Zhu, Yuying and Zhang, Yang and Liu, Lingbo and Liu, Yang and Li, Guanbin and Mao, Mingzhi and Lin, Liang},
  journal={IEEE Transactions on Industrial Informatics},
  year={2023}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: TFP -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/POI.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Urban Regional Function Guided Traffic Flow Prediction</h5>
                                <p class="pub-authors">Kuo Wang, Lingbo Liu, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Information Sciences (INS), 2023</p>
                                <div class="pub-links">
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0020025523004334" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibTFP" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibTFP">
@article{TFP,
  title = {Urban regional function guided traffic flow prediction},
  journal = {Information Sciences},
  year = {2023},
  author = {Kuo Wang and LingBo Liu and Yang Liu and GuanBin Li and Fan Zhou and Liang Lin},
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DADA -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/DADA.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Dual adversarial adaptation for cross-device real-world image super-resolution</h5>
                                <p class="pub-authors">Xiaoqian Xu, Pengxu Wei, Weikai Chen, <b>Yang Liu</b>, Mingzhi Mao, Liang Lin, Guanbin Li</p>
                                <p class="pub-venue">CVPR 2022 <span class="badge badge-hot">Oral</span></p>
                                <div class="pub-links">
                                    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/lonelyhope/DADA" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibDADA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/lonelyhope/DADA">
                                </div>
                                <div class="collapse bibtex-box" id="bibDADA">
@inproceedings{xu2022dual,
  title={Dual adversarial adaptation for cross-device real-world image super-resolution},
  author={Xu, Xiaoqian and Wei, Pengxu and Chen, Weikai and Liu, Yang and Mao, Mingzhi and Lin, Liang and Li, Guanbin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2022}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: MIR -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container ratio ratio-16x9">
                                <video muted="muted" autoplay loop playsinline src="img/MIR.mp4"></video>
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Causal Reasoning Meets Visual Representation Learning: A Prospective Study</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Yushen Wei, Hong Yan, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Machine Intelligence Research (MIR), 2022 <span class="badge badge-hot">Top-10 Downloads</span></p>
                                <div class="pub-links">
                                    <a href="https://link.springer.com/article/10.1007/s11633-022-1362-z" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://youtu.be/2lfNaTkcTHI" target="_blank"><i class="fab fa-youtube"></i> Video</a>
                                    <a href="https://mp.weixin.qq.com/s/-OlJ44DWE6nuX_OVyykURw" target="_blank"><i class="fab fa-weixin"></i> Interpretation</a>
                                    <a href="#bibMIR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/MIR">
                                </div>
                                <div class="collapse bibtex-box" id="bibMIR">
@article{liu2022causal,
  title={Causal Reasoning Meets Visual Representation Learning: A Prospective Study},
  author={Liu, Yang and Wei, Yu-Shen and Yan, Hong and Li, Guan-Bin and Lin, Liang},
  journal={Machine Intelligence Research},
  year={2022}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: VSAR -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/VSAR.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-modal knowledge distillation for Vision-to-Sensor action recognition</h5>
                                <p class="pub-authors">Jianyuan Ni, Raunak Sarbajna, <b>Yang Liu</b>, Anne HH Ngu, Yan Yan</p>
                                <p class="pub-venue">ICASSP 2022</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9746752" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibVSAR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibVSAR">
@inproceedings{ni2022cross,
  title={Cross-modal knowledge distillation for vision-to-sensor action recognition},
  author={Ni, Jianyuan and Sarbajna, Raunak and Liu, Yang and Ngu, Anne HH and Yan, Yan},
  booktitle={ICASSP},
  year={2022}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: TCGL -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/TCGL.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">TCGL: Temporal Contrastive Graph for Self-supervised Video Representation Learning</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Keze Wang, Lingbo Liu, Haoyuan Lan, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2022 <span class="badge badge-hot">ESI Highly Cited & Hot Paper</span></p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/9713748" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/YangLiu9208/TCGL/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibTCGL" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/TCGL">
                                </div>
                                <div class="collapse bibtex-box" id="bibTCGL">
@article{liu2022tcgl,
  title={TCGL: Temporal Contrastive Graph for Self-Supervised Video Representation Learning},
  author={Liu, Yang and Wang, Keze and Liu, Lingbo and Lan, Haoyuan and Lin, Liang},
  journal={IEEE Transactions on Image Processing},
  year={2022}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: SAKDN -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/SAKDN.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Keze Wang, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2021</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/9451581" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/YangLiu9208/SAKDN" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibSAKDN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/SAKDN">
                                </div>
                                <div class="collapse bibtex-box" id="bibSAKDN">
@article{liu2021semantics,
  title={Semantics-aware adaptive knowledge distillation for sensor-to-vision action recognition},
  author={Liu, Yang and Wang, Keze and Li, Guanbin and Lin, Liang},
  journal={IEEE Transactions on Image Processing},
  year={2021}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DIVAFN -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/TIP.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Zhaoyang Lu, Jing Li, Tao Yang, Chao Yao</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2020</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/8931264" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://yangliu9208.github.io/DIVAFN/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibDIVAFN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/DIVAFN">
                                </div>
                                <div class="collapse bibtex-box" id="bibDIVAFN">
@article{liu2019deep,
  title={Deep image-to-video adaptation and fusion networks for action recognition},
  author={Liu, Yang and Lu, Zhaoyang and Li, Jing and Yang, Tao and Yao, Chao},
  journal={IEEE Transactions on Image Processing},
  year={2019}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: JSRDA -->
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/TCSVT.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Hierarchically Learned View-Invariant Representations for Cross View Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Zhaoyang Lu, Jing Li, Tao Yang</p>
                                <p class="pub-venue">IEEE T-CSVT, 2019</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/8453034" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/YangLiu9208/JSRDA/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibJSRDA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/JSRDA">
                                </div>
                                <div class="collapse bibtex-box" id="bibJSRDA">
@article{liu2018hierarchically,
  title={Hierarchically learned view-invariant representations for cross-view action recognition},
  author={Liu, Yang and Lu, Zhaoyang and Li, Jing and Yang, Tao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2018}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                 <!-- Paper: TSTDDs -->
                 <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/SPL.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Global Temporal Representation based CNNs for Infrared Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Zhaoyang Lu, Jing Li, Tao Yang, Chao Yao</p>
                                <p class="pub-venue">IEEE Signal Processing Letters (SPL), 2018</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/8332532" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://yangliu9208.github.io/TSTDDs/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibTSTDDs" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/TSTDDs">
                                </div>
                                <div class="collapse bibtex-box" id="bibTSTDDs">
@article{liu2018global,
  title={Global temporal representation based cnns for infrared action recognition},
  author={Liu, Yang and Lu, Zhaoyang and Li, Jing and Yang, Tao and Yao, Chao},
  journal={IEEE Signal Processing Letters},
  year={2018}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- PhD Thesis -->
                <h3 class="mb-4 mt-5">PhD Dissertation</h3>
                <div class="pub-card card mb-4">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-3">
                            <div class="pub-img-container">
                                <img src="img/XD.gif" class="pub-img" alt="Thesis">
                            </div>
                        </div>
                        <div class="col-md-9">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-domain Human Action Recognition via Transfer Learning (基于迁移学习的跨域人体行为识别研究)</h5>
                                <p class="pub-authors"><b>Yang Liu</b> (Supervisor: Prof. Zhaoyang Lu)</p>
                                <p class="pub-venue">Xidian University, 2019</p>
                                <div class="pub-links">
                                    <a href="https://cdmd.cnki.com.cn/Article/CDMD-10701-1020000550.htm" target="_blank"><i class="fas fa-link"></i> Link</a>
                                    <a href="#bibPHD" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibPHD">
@phdthesis{刘阳2019基于迁移学习的跨域人体行为识别研究,
  title={基于迁移学习的跨域人体行为识别研究},
  author={刘阳},
  year={2019},
  school={西安电子科技大学}
}
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <hr class="m-0">

        <!-- Activities Section -->
        <section class="resume-section" id="activities">
            <div class="resume-section-content">
                <h2 class="mb-5">Academic Services</h2>
                
                <h4 class="mb-3">Reviewer for Journals</h4>
                <div class="row mb-4">
                    <div class="col-md-6">
                        <ul class="list-group list-group-flush">
                            <li class="list-group-item">IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                            <li class="list-group-item">IEEE Trans. on Image Processing (TIP)</li>
                            <li class="list-group-item">IEEE Trans. on Neural Networks and Learning Systems (TNNLS)</li>
                            <li class="list-group-item">IEEE Trans. on Cybernetics</li>
                            <li class="list-group-item">International Journal of Computer Vision (IJCV)</li>
                        </ul>
                    </div>
                    <div class="col-md-6">
                         <ul class="list-group list-group-flush">
                            <li class="list-group-item">ACM Trans. on Multimedia Computing Comm. and Applications</li>
                            <li class="list-group-item">Pattern Recognition (PR)</li>
                            <li class="list-group-item">Neural Networks</li>
                            <li class="list-group-item">Information Fusion</li>
                            <li class="list-group-item">Advanced Science</li>
                        </ul>
                    </div>
                </div>

                <h4 class="mb-3">Program Committee (PC) / Reviewer for Conferences</h4>
                <div class="row">
                     <div class="col-md-12">
                        <p>
                            <span class="badge bg-secondary m-1">CVPR</span>
                            <span class="badge bg-secondary m-1">ICCV</span>
                            <span class="badge bg-secondary m-1">ECCV</span>
                            <span class="badge bg-secondary m-1">NeurIPS</span>
                            <span class="badge bg-secondary m-1">ICML</span>
                            <span class="badge bg-secondary m-1">ICLR</span>
                            <span class="badge bg-secondary m-1">AAAI</span>
                            <span class="badge bg-secondary m-1">IJCAI</span>
                            <span class="badge bg-secondary m-1">ACM MM</span>
                            <span class="badge bg-secondary m-1">ICASSP</span>
                            <span class="badge bg-secondary m-1">UbiComp</span>
                            <span class="badge bg-secondary m-1">ISWC</span>
                        </p>
                     </div>
                </div>
            </div>
        </section>

    </div>

    <!-- Bootstrap 5 JS Bundle -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    
    <!-- Script to close navbar on mobile click -->
    <script>
        const navLinks = document.querySelectorAll('.js-scroll-trigger');
        const menuToggle = document.getElementById('navbarResponsive');
        const bsCollapse = new bootstrap.Collapse(menuToggle, {toggle:false});
        
        navLinks.forEach((l) => {
            l.addEventListener('click', () => {
                if (window.getComputedStyle(document.querySelector('.navbar-toggler')).display !== 'none') {
                    bsCollapse.hide();
                }
            });
        });
    </script>

</body>
</html>
