<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Academic Homepage of Yang Liu">
    <meta name="author" content="Yang Liu">
    <title>Yang Liu (刘阳) @ SYSU</title>

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,400&family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">

    <!-- Bootstrap 5 CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- FontAwesome Icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <!-- Academicons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <style>
        :root {
            --primary-bg: #f8f9fa;
            --sidebar-bg: #1e293b; /* Modern Slate Dark */
            --sidebar-text: #e2e8f0;
            --accent-color: #3b82f6; /* Modern Blue */
            --text-main: #334155;
            --text-dark: #0f172a;
            /* 增大侧边栏宽度以容纳大头像 */
            --sidebar-width: 20rem; 
            --transition-speed: 0.3s;
        }

        body {
            font-family: 'Merriweather', serif; /* Academic readable font */
            color: var(--text-main);
            background-color: #fff;
            line-height: 1.7;
        }

        h1, h2, h3, h4, h5, .nav-link, .badge, .btn {
            font-family: 'Roboto', sans-serif; /* Modern headings */
        }

        h1, h2 { color: var(--text-dark); font-weight: 700; }
        
        a {
            color: #2563eb;
            text-decoration: none;
            transition: all var(--transition-speed);
        }

        a:hover {
            color: #1e40af;
            text-decoration: underline;
        }

        /* --------------------------------------------------
           Sidebar / Navigation
        -------------------------------------------------- */
        .navbar-brand .img-profile {
            /* 头像尺寸放大 */
            width: 14rem;  
            height: 14rem;
            border: 6px solid rgba(255, 255, 255, 0.15); /* 边框稍微加粗 */
            border-radius: 50%;
            object-fit: cover;
            transition: transform var(--transition-speed);
            box-shadow: 0 6px 25px rgba(0,0,0,0.5);
            margin-bottom: 1rem;
        }

        @media (min-width: 992px) {
            body {
                padding-top: 0;
                padding-left: var(--sidebar-width);
            }

            .navbar {
                position: fixed;
                top: 0;
                left: 0;
                display: flex;
                flex-direction: column; /* 确保垂直排列 */
                width: var(--sidebar-width);
                height: 100vh;
                background-color: var(--sidebar-bg);
                text-align: center;
                box-shadow: 4px 0 15px rgba(0,0,0,0.1);
                /* 增加内边距让布局更舒展 */
                padding-top: 3rem; 
                padding-bottom: 3rem;
            }

            .navbar .container-fluid {
                display: flex;
                flex-direction: column;
                padding: 0;
                height: 100%;
                justify-content: flex-start; /* 内容从上往下排列 */
            }

            .navbar-brand { 
                padding: 0; 
                margin-bottom: 2rem; /* 头像和菜单之间的间距 */
            }

            .navbar-brand .img-profile:hover {
                transform: scale(1.03);
                border-color: var(--accent-color);
            }

            .navbar-collapse {
                display: flex !important;
                flex-direction: column;
                width: 100%;
                flex-grow: 0; /* 防止撑满 */
            }

            .navbar-nav {
                flex-direction: column !important; /* 强制垂直列表 */
                width: 100%;
            }

            .nav-item {
                width: 100%;
            }

            .nav-link {
                padding: 1.2rem 2rem; /* 增加点击区域 */
                color: rgba(255, 255, 255, 0.7);
                font-weight: 500;
                text-transform: uppercase;
                letter-spacing: 0.08rem;
                font-size: 1.05rem; /* 字体稍微调大 */
                border-left: 5px solid transparent;
                transition: all 0.2s;
                display: block; /* 块级元素占满一行 */
            }

            .nav-link:hover, .nav-link.active {
                color: #fff;
                background-color: rgba(255,255,255,0.08);
                border-left-color: var(--accent-color);
            }
        }

        @media (max-width: 991.98px) {
            body { padding-top: 80px; }
            .navbar { background-color: var(--sidebar-bg); padding: 0.5rem 1rem;}
            /* 移动端头像保持小尺寸，避免遮挡 */
            .navbar-brand .img-profile { width: 3.5rem; height: 3.5rem; border: 2px solid rgba(255,255,255,0.3); margin-bottom: 0; }
        }

        /* --------------------------------------------------
           Content Sections
        -------------------------------------------------- */
        section.resume-section {
            padding: 5rem 3rem;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            border-bottom: 1px solid #f1f5f9;
        }
        
        @media(max-width: 768px) {
            section.resume-section { padding: 3rem 1.5rem; }
        }

        section h2 {
            font-size: 3rem;
            margin-bottom: 3rem;
            position: relative;
        }
        
        section h2::after {
            content: '';
            display: block;
            width: 60px;
            height: 4px;
            background: var(--accent-color);
            margin-top: 10px;
            border-radius: 2px;
        }

        /* --------------------------------------------------
           About & Intro
        -------------------------------------------------- */
        .subheading {
            font-family: 'Roboto', sans-serif;
            text-transform: uppercase;
            font-weight: 700;
            font-size: 1.2rem;
            color: var(--accent-color);
            margin-bottom: 1.5rem;
        }

        .interest-tag {
            background-color: #f1f5f9;
            color: #475569;
            padding: 6px 16px;
            border-radius: 50px;
            font-size: 0.9rem;
            font-weight: 500;
            font-family: 'Roboto', sans-serif;
            margin-bottom: 0.6rem;
            margin-right: 0.4rem;
            display: inline-block;
            transition: all 0.2s;
            border: 1px solid #e2e8f0;
        }
        .interest-tag:hover {
            background-color: var(--sidebar-bg);
            color: #fff;
            border-color: var(--sidebar-bg);
            transform: translateY(-2px);
        }

        .social-icons a {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            height: 3.5rem;
            width: 3.5rem;
            background-color: #334155;
            color: #fff !important;
            border-radius: 50%;
            font-size: 1.5rem;
            margin-right: 1rem;
            transition: transform 0.2s, background-color 0.2s;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        .social-icons a:hover {
            background-color: var(--accent-color);
            transform: translateY(-5px);
        }

        /* --------------------------------------------------
           News Section (Timeline Style)
        -------------------------------------------------- */
        .news-box {
            max-height: 550px;
            overflow-y: auto;
            background: #fff;
            padding: 10px 20px;
            border-radius: 8px;
            /* Minimalist Scrollbar */
            scrollbar-width: thin;
            scrollbar-color: #cbd5e1 transparent;
        }
        .news-box::-webkit-scrollbar { width: 6px; }
        .news-box::-webkit-scrollbar-thumb { background-color: #cbd5e1; border-radius: 20px; }

        .news-list {
            position: relative;
            padding-left: 20px;
            border-left: 2px solid #e2e8f0;
        }

        .news-list li {
            position: relative;
            margin-bottom: 20px;
            padding-left: 20px;
        }

        .news-list li::before {
            content: '';
            position: absolute;
            left: -26px; /* Adjust based on border and padding */
            top: 6px;
            width: 10px;
            height: 10px;
            background: var(--accent-color);
            border-radius: 50%;
            border: 2px solid #fff;
            box-shadow: 0 0 0 2px #e2e8f0;
        }

        .news-date {
            font-family: 'Roboto', sans-serif;
            font-weight: 700;
            color: #334155;
            background: #f1f5f9;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.85rem;
            margin-right: 10px;
            vertical-align: middle;
        }

        /* --------------------------------------------------
           Publications Enhanced (Larger Images)
        -------------------------------------------------- */
        .pub-card {
            background: #fff;
            border: 1px solid rgba(0,0,0,0.05);
            border-radius: 12px;
            margin-bottom: 3rem;
            transition: all 0.3s cubic-bezier(0.165, 0.84, 0.44, 1);
            overflow: hidden;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);
        }

        .pub-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
            border-color: rgba(59, 130, 246, 0.3); /* Accent border on hover */
        }

        .pub-img-container {
            width: 100%;
            height: 100%;
            min-height: 220px; /* Increased height */
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #f8fafc;
            border-right: 1px solid #f1f5f9;
            overflow: hidden;
            padding: 0;
        }

        .pub-img {
            width: 100%;
            height: 100%;
            object-fit: cover; 
            transition: transform 0.6s ease;
        }
        
        .pub-card:hover .pub-img {
            transform: scale(1.03);
        }

        .card-body { padding: 2rem; }

        .pub-title {
            font-family: 'Roboto', sans-serif;
            font-size: 1.4rem; 
            font-weight: 700;
            margin-bottom: 0.8rem;
            color: #0f172a;
            line-height: 1.3;
        }

        .pub-authors {
            font-size: 1.05rem;
            color: #475569;
            margin-bottom: 0.8rem;
        }

        .pub-authors b {
            color: #0f172a;
            text-decoration: underline;
            text-decoration-color: #94a3b8;
            text-underline-offset: 3px;
        }

        .pub-venue {
            font-size: 1rem;
            color: #64748b;
            margin-bottom: 1.2rem;
            font-style: italic;
        }
        
        .badge {
            font-weight: 600;
            padding: 0.45em 0.7em;
            letter-spacing: 0.5px;
            vertical-align: middle;
        }
        .badge-hot { background-color: #fee2e2; color: #991b1b; border: 1px solid #fecaca; }
        .badge-oral { background-color: #e0f2fe; color: #075985; border: 1px solid #bae6fd; }
        .badge-highlight { background-color: #fef3c7; color: #92400e; border: 1px solid #fde68a; }
        .text-bg-success { background-color: #dcfce7 !important; color: #166534 !important; border: 1px solid #bbf7d0; }

        .pub-links a {
            font-family: 'Roboto', sans-serif;
            font-size: 0.8rem;
            font-weight: 600;
            display: inline-flex;
            align-items: center;
            padding: 6px 16px;
            margin-right: 8px;
            margin-bottom: 8px;
            border-radius: 50px; /* Pill shape */
            background-color: #fff;
            border: 1px solid #cbd5e1;
            color: #475569;
            text-transform: uppercase;
            transition: all 0.2s;
        }

        .pub-links a:hover {
            background-color: #1e293b;
            color: #fff;
            border-color: #1e293b;
            text-decoration: none;
        }

        .github-badges {
            margin-top: 12px;
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }
        .github-badges img {
            height: 22px;
            opacity: 0.9;
            transition: opacity 0.2s;
        }
        .github-badges img:hover { opacity: 1.0; }
        
        .bibtex-box {
            background-color: #f1f5f9;
            color: #334155;
            padding: 1rem;
            border: 1px solid #e2e8f0;
            border-radius: 6px;
            font-size: 0.85rem;
            margin-top: 15px;
            font-family: 'Courier New', monospace;
            white-space: pre-wrap;
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.03);
        }
        
        /* --------------------------------------------------
           Activities
        -------------------------------------------------- */
        .service-card {
            background: #fff;
            padding: 2.5rem;
            border-radius: 12px;
            border: 1px solid #e2e8f0;
            box-shadow: 0 4px 6px -1px rgba(0,0,0,0.05);
            height: 100%;
        }
        .service-card h4 {
            border-bottom: 2px solid #f1f5f9;
            padding-bottom: 15px;
            margin-bottom: 20px;
            color: #1e293b;
            font-weight: 700;
        }
        .list-group-item {
            border: none;
            padding: 0.6rem 0;
            font-size: 1.05rem;
            color: #475569;
        }
        .badge-conf {
            display: inline-block;
            background-color: #f8fafc;
            color: #334155;
            border: 1px solid #cbd5e1;
            padding: 8px 14px;
            font-size: 0.9rem;
            font-weight: 600;
            border-radius: 6px;
            margin-bottom: 8px;
            font-family: 'Roboto', sans-serif;
            transition: all 0.2s;
        }
        .badge-conf:hover {
            background-color: #e2e8f0;
            color: #0f172a;
        }
    </style>
</head>

<body id="page-top" data-bs-spy="scroll" data-bs-target="#sideNav" data-bs-offset="0" tabindex="0">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="sideNav">
        <div class="container-fluid">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Yang Liu</span>
                <span class="d-none d-lg-block">
                    <img class="img-fluid img-profile rounded-circle mx-auto" src="./img/ArYanR2026.png" alt="Yang Liu Profile">
                </span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">Introduction</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#news">News</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#activities">Activities</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <div class="container-fluid p-0">

        <!-- About Section -->
        <section class="resume-section" id="about">
            <div class="resume-section-content">
                <h1 class="mb-2 display-4 fw-bold">Yang Liu <span class="h3 fw-light text-secondary">(刘阳)</span></h1>
                <div class="subheading mb-4">
                    Associate Professor @ Sun Yat-sen University (SYSU)
                </div>
                
                <div class="row mb-5">
                    <div class="col-lg-8">
                        <p class="lead mb-4" style="color: #475569;">
                            <i class="fas fa-envelope me-2" style="color:#64748b;"></i> liuy856@mail.sysu.edu.cn<br>
                            <i class="fas fa-university me-2" style="color:#64748b;"></i> School of Computer Science and Engineering, SYSU, Guangzhou, China<br>
                            <i class="fas fa-users me-2" style="color:#64748b;"></i> HCP-Lab
                        </p>
                        <p class="mb-4 text-justify">
                            I am currently an Associate Professor at the <a href="http://sdcs.sysu.edu.cn/" target="_blank">School of Computer Science and Engineering</a>, <a href="http://www.sysu.edu.cn/" target="_blank">Sun Yat-sen University (SYSU)</a>. I am a core member of the <a href="http://www.sysu-hcp.net/" target="_blank" class="fw-bold text-dark">HCP Lab</a> led by Prof. Liang Lin. 
                            I obtained my Ph.D. degree from Xidian University in 2019. 
                        </p>
                        <p class="mb-4 text-justify">
                            My research primarily focuses on <b>Embodied AI</b>, <b>Multimodal Spatial Perception & Reasoning</b>, and <b>Causal Inference</b>. 
                            I have published over 50 papers in top-tier conferences and journals, including TPAMI, TIP, TMECH, TKDE, CVPR, ICCV, and ACM MM. 
                            Several of my works have been selected as Oral/Highlight presentations or ESI Highly Cited Papers. 
                            I also authored the book <i>"Multimodal Large Models: The New Paradigm of Artificial General Intelligence"</i>.
                            <a href="https://cse.sysu.edu.cn/teacher/LiuYang" target="_blank" class="badge bg-secondary text-decoration-none ms-2"><i class="fas fa-language"></i> 中文主页</a>
                        </p>
                        
                        <div class="alert alert-light border shadow-sm rounded-3" style="background-color: #f8fafc; border-color: #e2e8f0;" role="alert">
                            <h5 class="alert-heading fw-bold" style="color: #1e293b;"><i class="fas fa-bullhorn me-2 text-warning"></i>Recruiting</h5>
                            <hr>
                            <p class="mb-0 small" style="color: #334155;">
                                Our team has sufficient computing resources and robotic hardware. 
                                I am looking for self-motivated <b>Ph.D. students, Master students, and Research Interns</b> who are interested in Embodied AI and Multimodal Reasoning. 
                                Please email me your CV if interested.
                            </p>
                        </div>
                    </div>
                    <div class="col-lg-4 text-center d-flex align-items-center justify-content-center">
                        <!-- Visitor Map -->
                        <div style="transform: scale(0.9); border: 1px solid #e2e8f0; padding: 10px; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.05);">
                            <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=m&d=Ng_LP0UrQP5gWGJEym9UVNi8Up0eZ-cQXq9wH1Me7Bg"></script>
                        </div>
                    </div>
                </div>

                <div class="row">
                    <div class="col-md-6 mb-4">
                        <h3 class="h4 mb-3 pb-2 border-bottom">Research Interests</h3>
                        <div>
                            <span class="interest-tag"><i class="fas fa-robot me-1"></i> Embodied AI</span>
                            <span class="interest-tag"><i class="fas fa-cubes me-1"></i> 3D Spatial Reasoning</span>
                            <span class="interest-tag"><i class="fas fa-map-marked-alt me-1"></i> VL Navigation</span>
                            <span class="interest-tag"><i class="fas fa-brain me-1"></i> Causal Inference</span>
                            <span class="interest-tag"><i class="fas fa-hand-paper me-1"></i> Robotic Manipulation</span>
                        </div>
                    </div>
                    <div class="col-md-6 mb-4">
                        <h3 class="h4 mb-3 pb-2 border-bottom">Selected Awards</h3>
                        <ul class="fa-ul list-awards" style="color: #475569;">
                            <li><span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>Outstanding Teaching Achievement of Guangdong Province (2nd Prize), 2025</li>
                            <li><span class="fa-li"><i class="fas fa-award text-secondary"></i></span>Excellent Author of PHE (Publishing House of Electronics Industry), 2024</li>
                            <li><span class="fa-li"><i class="fas fa-award text-secondary"></i></span>CCF ChinaSoft 2023 Challenge (3rd Prize)</li>
                            <li><span class="fa-li"><i class="fas fa-award text-secondary"></i></span>3rd Guangdong Province Young CS Academic Show (1st Prize), 2023</li>
                            <li><span class="fa-li"><i class="fas fa-award text-secondary"></i></span>National Scholarship for PhD Students, 2018</li>
                        </ul>
                    </div>
                </div>

                <div class="social-icons mt-4">
                    <a href="https://scholar.google.com/citations?user=l0z2QNQAAAAJ&hl=en" target="_blank" title="Google Scholar">
                        <i class="ai ai-google-scholar"></i>
                    </a>
                    <a href="https://github.com/YangLiu9208" target="_blank" title="GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                    <a href="https://dblp.uni-trier.de/pid/51/3710-84.html" target="_blank" title="DBLP">
                        <i class="ai ai-dblp"></i>
                    </a>
                    <a href="https://www.researchgate.net/profile/Yang-Liu-30" target="_blank" title="ResearchGate">
                        <i class="ai ai-researchgate"></i>
                    </a>
                </div>
            </div>
        </section>

        <!-- News Section -->
        <section class="resume-section bg-light" id="news">
            <div class="resume-section-content">
                <h2 class="mb-5">News</h2>
                <div class="news-box shadow-sm">
                    <ul class="list-unstyled news-list">
                        <li><span class="news-date">2026-02</span> Three papers are accepted by <b>CVPR 2026</b>!</li>
                        <li><span class="news-date">2026-02</span> The book "Multimodal Large Models: A New Paradigm of Artificial Intelligence" has now been published on <b>Springer Nature</b>!</li>
                        <li><span class="news-date">2025-11</span> One T-IP paper is selected as the <b>ESI Highly Cited Paper</b>!</li>
                        <li><span class="news-date">2025-09</span> Two papers are accepted by <b>NeurIPS 2025</b>!</li>
                        <li><span class="news-date">2025-08</span> One paper is accepted by <b>Neural Networks</b>!</li>
                        <li><span class="news-date">2025-07</span> One paper is accepted by <b>ACM MM 2025</b> as <span class="badge badge-hot text-dark">Oral</span>!</li>
                        <li><span class="news-date">2025-06</span> One paper is accepted by <b>ICCV 2025</b>!</li>
                        <li><span class="news-date">2025-06</span> One paper is accepted by <b>IEEE TKDE</b>!</li>
                        <li><span class="news-date">2025-05</span> Our Embodied AI Survey paper is accepted by <b>IEEE/ASME T-Mechatronics</b>!</li>
                        <li><span class="news-date">2025-05</span> One paper is accepted by <b>ACL 2025</b>!</li>
                        <li><span class="news-date">2025-05</span> Paper "Cross-Modal Causal Representation Learning..." accepted by <b>IEEE T-IP</b>!</li>
                        <li><span class="news-date">2025-04</span> Our CRA-GQA is selected as <b>CVPR 2025</b> <span class="badge badge-highlight text-dark">Highlight</span>!</li>
                        <li><span class="news-date">2025-02</span> Three papers are accepted by <b>CVPR 2025</b>!</li>
                        <li><span class="news-date">2024-07</span> We release the <a href="https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List" target="_blank" class="fw-bold">paper list</a> for Embodied AI!</li>
                        <li><span class="news-date">2024-07</span> One paper is accepted by <b>ACM MM 2024</b>!</li>
                        <li><span class="news-date">2024-06</span> The book <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank">《多模态大模型：新一代人工智能技术范式》</a> is selected for the SYSU Undergraduate Textbook Series!</li>
                        <li><span class="news-date">2024-05</span> One first-author T-PAMI paper is selected as the <b>ESI Hot Cited Paper</b>!</li>
                        <li><span class="news-date">2024-05</span> One first-author T-PAMI paper is selected as the <b>ESI Highly Cited Paper</b>!</li>
                        <li><span class="news-date">2024-04</span> The book of multimodal large model <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank">《多模态大模型：新一代人工智能技术范式》</a> is published!</li>
                        <li><span class="news-date">2023-12</span> I won the third prize of CCF ChinaSoft 2023 Robotic Big Model and Embodied Intelligence Challenge!</li>
                        <li><span class="news-date">2023-11</span> One first-author T-IP paper is selected as the <b>ESI Hot Cited Paper</b>!</li>
                        <li><span class="news-date">2023-10</span> An invention patent has been granted.</li>
                        <li><span class="news-date">2023-07</span> One paper accepted by <b>ACM MM 2023</b>!</li>
                        <li><span class="news-date">2023-07</span> Two papers accepted by <b>ICCV 2023</b>!</li>
                        <li><span class="news-date">2023-06</span> One paper accepted by <b>T-PAMI</b>!</li>
                        <li><span class="news-date">2023-03</span> The open-source framework <a href="https://github.com/YangLiu9208/Causal-VLReasoning" target="_blank">Causal-VLReasoning</a> is online!</li>
                        <li><span class="news-date">2022-03</span> One paper accepted by <b>CVPR 2022</b> as <span class="badge badge-oral text-dark">Oral</span> presentation.</li>
                        <li><span class="news-date">2021-10</span> I start working as a research associate professor at Sun-Yat-Sen University.</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Publications Section -->
        <section class="resume-section" id="publications">
            <div class="resume-section-content">
                <h2 class="mb-5">Publications</h2>

                <!-- Books -->
                <h3 class="mb-4 text-muted" style="border-left: 5px solid #1e293b; padding-left: 15px;">Books</h3>
                
                <!-- Book 1 -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <!-- Changed col-md-3 to col-md-4 for larger images -->
                        <div class="col-md-4 text-center">
                            <div class="pub-img-container">
                                <img src="img/PHE.jpg" class="pub-img" alt="Book Cover">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Multimodal Large Models: The New Paradigm of Artificial General Intelligence</h5>
                                <h6 class="card-subtitle mb-2 text-muted">《多模态大模型：新一代人工智能技术范式》</h6>
                                <p class="pub-authors"><b>Yang Liu</b>, Liang Lin</p>
                                <p class="pub-venue">Publishing House of Electronics Industry (PHE), 2024. <span class="badge text-bg-success">Textbook Series</span></p>
                                <div class="pub-links">
                                    <a href="https://hcplab-sysu.github.io/Book-of-MLM/" target="_blank"><i class="fas fa-globe"></i> Resource</a>
                                    <a href="https://item.jd.com/10100489294930.html" target="_blank"><i class="fas fa-shopping-cart"></i> JD.com</a>
                                    <a href="https://mp.weixin.qq.com/s/WHYy-dlJl6V4TQoZxWIiYQ" target="_blank"><i class="fab fa-weixin"></i> Media</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/Book-of-MLM?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/Book-of-MLM?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/Book-of-MLM?style=social">
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Book 2 -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4 text-center">
                            <div class="pub-img-container">
                                <img src="img/PHE-ENG.png" class="pub-img" alt="Book Cover">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Multimodal Large Models: A New Paradigm of Artificial Intelligence</h5>
                                <p class="pub-authors">Liang Lin, <b>Yang Liu</b></p>
                                <p class="pub-venue">Springer Nature, 2026.</p>
                                <div class="pub-links">
                                    <a href="https://link.springer.com/book/10.1007/978-981-95-4929-0" target="_blank"><i class="fas fa-globe"></i> Book</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Open Source Framework -->
                <h3 class="mb-4 mt-5 text-muted" style="border-left: 5px solid #1e293b; padding-left: 15px;">Open-source Framework</h3>
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4 text-center">
                            <div class="pub-img-container">
                                <img src="img/CausalVLR.gif" class="pub-img" alt="Framework Demo">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">CausalVLR: A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Weixing Chen, Guanbin Li, Liang Lin</p>
                                <p class="card-text text-muted small mb-3">CausalVLR is a python open-source framework for causal relation discovery and inference, implementing SOTA causality learning algorithms for various visual-linguistic reasoning tasks.</p>
                                <div class="pub-links">
                                    <a href="https://github.com/HCPLab-SYSU/CausalVLR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="https://arxiv.org/pdf/2306.17462.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibCausal" data-bs-toggle="collapse" role="button" aria-expanded="false"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CausalVLR?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/CausalVLR?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/CausalVLR?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibCausal">
@article{CausalVLR,
  title={CausalVLR: A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning},
  author={Liu, Yang and Chen, Weixing and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2306.17462},
  year={2023}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Papers List -->
                <h3 class="mb-4 mt-5 text-muted" style="border-left: 5px solid #1e293b; padding-left: 15px;">Selected Papers</h3>
<!-- Paper: DDP-WM -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/DDP-WM.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">DDP-WM: Disentangled Dynamics Prediction for Efficient World Models</h5>
                                <p class="pub-authors">Shicheng Yin#, Kaixuan Yin#, Weixing Chen, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Preprint, 2026</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/abs/2602.01780" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/DDP-WM" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibDDP-WM" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/DDP-WM?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/DDP-WM?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/DDP-WM?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibDDP-WM">
</div>
                            </div>
                        </div>
                    </div>
                </div>

                    <!-- Paper: TAVP -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/TAVP.jpg" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Learning to See and Act: Task-Aware Virtual View Exploration for Robotic Manipulation</h5>
                                <p class="pub-authors">Yongjie Bai#, Zhouxia Wang#, <b>Yang Liu</b><sup>✉</sup>, Kaijun Luo, Yifan Wen, Mingtong Dai, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2026</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2508.05186" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/TAVP/" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibTAVP" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/TAVP?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/TAVP?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/TAVP?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibTAVP">
@article{bai2025learning,
  title={Learning to See and Act: Task-Aware Virtual View Exploration for Robotic Manipulation},
  author={Bai, Yongjie and Wang, Zhouxia and Liu, Yang and Luo, Kaijun and Wen, Yifan and Dai, Mingtong and Chen, Weixing and Chen, Ziliang and Liu, Lingbo and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2508.05186},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Paper: 3DAffordSplat -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/3DAffordSplat.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians</h5>
                                <p class="pub-authors">Zeming Wei#, Junyi Lin#, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">ACM International Conference on Multimedia (ACM MM), 2025 <span class="badge badge-oral">Oral</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2504.11218" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/3DAffordSplat/" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bib3DAffordSplat" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/3DAffordSplat?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/3DAffordSplat?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/3DAffordSplat?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bib3DAffordSplat">
@article{3DAffordSplat,
  title={3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians},
  author={Wei, Zeming and Lin, Junyi and Liu, Yang and Chen, Weixing and Luo, Jingzhou and Li, Guanbin and Lin, Liang},
  year={2025},
  journal={arXiv preprint arXiv:2504.11218}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: EXPRESS-Bench -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/EXPRESS-Bench.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering</h5>
                                <p class="pub-authors">Kaixuan Jiang, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Jingzhou Luo, Ziliang Chen, Ling Pan, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2503.11117" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/EXPRESS-Bench/" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibEXPRESS" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/EXPRESS-Bench?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/EXPRESS-Bench?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/EXPRESS-Bench?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibEXPRESS">
@inproceedings{EXPRESSBench,
  title={Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering},
  author={Jiang, Kaixuan and Liu, Yang and Chen, Weixing and Luo, Jingzhou and Chen, Ziliang and Pan, Ling and Li, Guanbin and Lin, Liang},
  year={2025},
  booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: Embodied Survey -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/Embodied_survey.jpg" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Weixing Chen, Yongjie Bai, Xiaodan Liang, Guanbin Li, Wen Gao, Liang Lin</p>
                                <p class="pub-venue">IEEE/ASME Transactions on Mechatronics, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2407.06886" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List" target="_blank"><i class="fab fa-github"></i> Paper List</a>
                                    <a href="#bibEmbodiedSurvey" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/Embodied_AI_Paper_List?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/Embodied_AI_Paper_List?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/Embodied_AI_Paper_List?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibEmbodiedSurvey">
@article{liu2024aligning,
  title={Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI},
  author={Liu, Yang and Chen, Weixing and Bai, Yongjie and Liang, Xiaodan and Li, Guanbin and Gao, Wen and Lin, Liang},
  journal={arXiv preprint arXiv:2407.06886},
  year={2024}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: VLCI -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/VLCI.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-Modal Causal Representation Learning for Radiology Report Generation</h5>
                                <p class="pub-authors">Weixing Chen, <b>Yang Liu</b><sup>✉</sup>, Ce Wang, Jiarui Zhu, Guanbin Li, Cheng-Lin Liu, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2025 <span class="badge badge-hot">ESI Highly Cited</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2303.09117" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/WissingChen/VLCI" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibVLCI" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/WissingChen/VLCI?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/WissingChen/VLCI?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/WissingChen/VLCI?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibVLCI">
@article{chen2025visual,
  title={Cross-Modal Causal Representation Learning for Radiology Report Generation},
  author={Chen, Weixing and Liu, Yang and Wang, Ce and Zhu, Jiarui and Li, Guanbin and Liu, Cheng-Lin and Lin, Liang},
  journal={IEEE Transactions on Image Processing},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: ODMixer -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/ODMixer.jpg" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">ODMixer: Fine-grained Spatial-temporal MLP for Metro Origin-Destination Prediction</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Binglin Chen, Yongsen Zheng, Lechao Cheng, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Knowledge and Data Engineering (TKDE), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2404.15734" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/KLatitude/ODMixer" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibODMixer" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/KLatitude/ODMixer?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/KLatitude/ODMixer?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/KLatitude/ODMixer?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibODMixer">
@article{liu2024fine,
  title={ODMixer: Fine-grained Spatial-temporal MLP for Metro Origin-Destination Prediction},
  author={Liu, Yang and Chen, Binglin and Zheng, Yongsen and Cheng, Lechao and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2404.15734},
  year={2024}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

            

                <!-- Paper: AutoLayout -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/AutoLayout.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning</h5>
                                <p class="pub-authors">Weixing Chen, Dafeng Chi, <b>Yang Liu</b><sup>✉</sup>, Yuxi Yang, Yexin Zhang, Yuzheng Zhuang, Xingyue Quan, Jianye Hao, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Preprint, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2507.04293" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibAutoLayout" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibAutoLayout">
@article{chen2025autolayout,
  title={AutoLayout: Closed-Loop Layout Synthesis via Slow-Fast Collaborative Reasoning},
  author={Chen, Weixing and Chi, Dafeng and Liu, Yang and Yang, Yuxi and Zhang, Yexin and Zhuang, Yuzheng and Quan, Xingyue and Hao, Jianye and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2507.04293},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DART -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/DART.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Foundation Models</h5>
                                <p class="pub-authors">Shicheng Yin, Kaixuan Yin, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Liang Lin</p>
                                <p class="pub-venue">Preprint, 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2506.10390" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/DART" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibDART" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/DART?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/DART?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/DART?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibDART">
@article{yin2025dart,
  title={DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba},
  author={Shicheng Yin and Kaixuan Yin and Yang Liu and Weixing Chen and Liang Lin},
  journal={arXiv preprint arXiv:2506.10390},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: LHPR-VLN -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/LHPR-VLN.gif" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method</h5>
                                <p class="pub-authors">Xinshuai Song*, Weixing Chen*, <b>Yang Liu</b><sup>✉</sup>, Weikai Chen, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2412.09082" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://hcplab-sysu.github.io/LH-VLN" target="_blank"><i class="fas fa-globe"></i> Project</a>
                                    <a href="#bibLHVLN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/LH-VLN?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/LH-VLN?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/LH-VLN?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibLHVLN">
@inproceedings{song2024towards,
  title={Towards long-horizon vision-language navigation: Platform, benchmark and method},
  author={Song, Xinshuai and Chen, Weixing and Liu, Yang and Chen, Weikai and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DSPNet -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/DSPNet.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering</h5>
                                <p class="pub-authors">Jingzhou Luo, <b>Yang Liu</b><sup>✉</sup>, Weixing Chen, Zhen Li, Yaowei Wang, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2503.03190" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/LZ-CH/DSPNet" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibDSPNet" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/LZ-CH/DSPNet?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/LZ-CH/DSPNet?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/LZ-CH/DSPNet?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibDSPNet">
@inproceedings{luo2025dspnet,
  title={DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering},
  author={Luo, Jingzhou and Liu, Yang and Chen, Weixing and Li, Zhen and Wang, Yaowei and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CRA-GQA -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/CRA.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-modal Causal Relation Alignment for Video Question Grounding</h5>
                                <p class="pub-authors">Weixing Chen, <b>Yang Liu</b><sup>✉</sup>, Binglin Chen, Jiandong Su, Yongsen Zheng, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025 <span class="badge badge-highlight">Highlight</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2503.07635" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/WissingChen/CRA-GQA" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibCRA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/WissingChen/CRA-GQA?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/WissingChen/CRA-GQA?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/WissingChen/CRA-GQA?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibCRA">
@inproceedings{chen2025cross,
  title={Cross-modal Causal Relation Alignment for Video Question Grounding},
  author={Chen, Weixing and Liu, Yang and Chen, Binglin and Su, Jiandong and Zheng, Yongsen and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: InfiniteWorld -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/InfiniteWorld.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">InfiniteWorld: A Unified Scalable Simulation Framework for General Visual-Language Robot Interaction</h5>
                                <p class="pub-authors">Pengzhen Ren, Min Li, Zhen Luo, Xinshuai Song, Ziwei Chen, Weijia Liufu, Yixuan Yang, Hao Zheng, Rongtao Xu, Zitong Huang, Tongsheng Ding, Luyang Xie, Kaidong Zhang, Changfei Fu, <b>Yang Liu</b>, Liang Lin, Feng Zheng, Xiaodan Liang</p>
                                <p class="pub-venue">arXiv preprint:2412.05789, 2024</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2412.05789" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/pzhren/InfiniteWorld" target="_blank"><i class="fab fa-github"></i> Project</a>
                                    <a href="#bibInfiniteWorld" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/pzhren/InfiniteWorld?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/pzhren/InfiniteWorld?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/pzhren/InfiniteWorld?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibInfiniteWorld">
@article{ren2024infiniteworld,
  title={InfiniteWorld: A Unified Scalable Simulation Framework for General Visual-Language Robot Interaction},
  author={Ren, Pengzhen and Li, Min and Luo, Zhen and Song, Xinshuai and Chen, Ziwei and Liufu, Weijia and Yang, Yixuan and Zheng, Hao and Xu, Rongtao and Huang, Zitong and others},
  journal={arXiv preprint arXiv:2412.05789},
  year={2024}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CMCIR -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/VLCIR.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2023 <span class="badge badge-hot">ESI Highly Cited & Hot</span></p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/10146482" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/CMCIR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibCMCIR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CMCIR?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/CMCIR?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/CMCIR?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibCMCIR">
@article{liu2022cross,
  author={Liu, Yang and Li, Guanbin and Lin, Liang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering}, 
  year={2023},
  doi={10.1109/TPAMI.2023.3284038}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CRS -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/CRS.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Diversity Matters: User-Centric Multi-Interest Learning for Conversational Movie Recommendation</h5>
                                <p class="pub-authors">Yongsen Zheng, Guohua Wang, <b>Yang Liu</b>, Liang Lin</p>
                                <p class="pub-venue">ACM International Conference on Multimedia (ACM MM), 2024</p>
                                <div class="pub-links">
                                    <a href="https://yangliu9208.github.io/" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: MEIA -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/MEIA.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">MEIA: Multimodal Embodied Perception and Interaction in Unknown Environments</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Xinshuai Song, Kaixuan Jiang, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">arXiv preprint:2402.00290, 2024</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2402.00290v2" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibMEIA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibMEIA">
@article{liu2024multimodal,
  title={MEIA: Multimodal Embodied Perception and Interaction in Unknown Environments},
  author={Liu, Yang and Song, Xinshuai and Jiang, Kaixuan and Chen, Weixing and Luo, Jingzhou and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2402.00290},
  year={2024}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: CausalGPT -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/CaCoCoT.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">CausalGPT: Illuminating Faithfulness and Causality for Knowledge-based Reasoning with LLMs</h5>
                                <p class="pub-authors">Ziyi Tang, Ruilin Wang, Weixing Chen, Yongsen Zheng, <b>Yang Liu</b>, Keze Wang, Tianshui Chen, Liang Lin</p>
                                <p class="pub-venue">arXiv preprint:2308.11914, 2023</p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2308.11914.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/CausalVLR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibCausalGPT" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CausalVLR?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/CausalVLR?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/CausalVLR?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibCausalGPT">
@article{tang2023towards,
  title={Towards causalgpt: A multi-agent approach for faithful knowledge reasoning via promoting causal consistency in llms},
  author={Tang, Ziyi and Wang, Ruilin and Chen, Weixing and Wang, Keze and Liu, Yang and Chen, Tianshui and Lin, Liang},
  journal={arXiv preprint arXiv:2308.11914},
  year={2023}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: VCSR -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/VCSR.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Visual Causal Scene Refinement for Video Question Answering</h5>
                                <p class="pub-authors">Yushen Wei*, <b>Yang Liu*</b>, Hong Yan, Guanbin Li, Liang Lin<sup>✉</sup></p>
                                <p class="pub-venue">ACM International Conference on Multimedia (ACM MM), 2023 <span class="badge badge-oral">Oral</span></p>
                                <div class="pub-links">
                                    <a href="https://arxiv.org/pdf/2305.04224.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HCPLab-SYSU/CausalVLR" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibVCSR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HCPLab-SYSU/CausalVLR?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HCPLab-SYSU/CausalVLR?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HCPLab-SYSU/CausalVLR?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibVCSR">
@inproceedings{10.1145/3581783.3611873,
  author = {Wei, Yushen and Liu, Yang and Yan, Hong and Li, Guanbin and Lin, Liang},
  title = {Visual Causal Scene Refinement for Video Question Answering},
  year = {2023},
  series = {MM '23}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: SkeletonMAE -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/SkeletonMAE.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">SkeletonMAE: Graph-based Masked Autoencoder for Skeleton Sequence Pre-training</h5>
                                <p class="pub-authors">Hong Yan, <b>Yang Liu</b><sup>✉</sup>, Yushen Wei, Zhen Li, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2023</p>
                                <div class="pub-links">
                                    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/HongYan1123/SkeletonMAE" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibSkeletonMAE" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/HongYan1123/SkeletonMAE?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/HongYan1123/SkeletonMAE?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/HongYan1123/SkeletonMAE?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibSkeletonMAE">
@inproceedings{yan2023skeletonmae,
  title={Skeletonmae: graph-based masked autoencoder for skeleton sequence pre-training},
  author={Yan, Hong and Liu, Yang and Wei, Yushen and Li, Zhen and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: ESL -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/ESL.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Enhanced Soft Label for Semi-Supervised Semantic Segmentation</h5>
                                <p class="pub-authors">Jie Ma, Chuan Wang, <b>Yang Liu</b>, Liang Lin, Guanbin Li</p>
                                <p class="pub-venue">IEEE/CVF International Conference on Computer Vision (ICCV), 2023</p>
                                <div class="pub-links">
                                    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/unrealMJ/ESL" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibESL" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/unrealMJ/ESL?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/unrealMJ/ESL?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/unrealMJ/ESL?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibESL">
@inproceedings{ma2023enhanced,
  title={Enhanced Soft Label for Semi-Supervised Semantic Segmentation},
  author={Ma, Jie and Wang, Chuan and Liu, Yang and Lin, Liang and Li, Guanbin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2023}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DenseLight -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/DenseLight.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">DenseLight: Efficient Control for Large-scale Traffic Signals with Dense Feedback</h5>
                                <p class="pub-authors">Junfan Lin, Yuying Zhu, Lingbo Liu, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">International Joint Conference on Artificial Intelligence (IJCAI), 2023</p>
                                <div class="pub-links">
                                    <a href="https://yangliu9208.github.io/home/" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/junfanlin/DenseLight" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibDenseLight" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/junfanlin/DenseLight?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/junfanlin/DenseLight?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/junfanlin/DenseLight?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibDenseLight">
@inproceedings{ijcai2023p672,
  title={DenseLight: Efficient Control for Large-scale Traffic Signals with Dense Feedback},
  author={Lin, Junfan and Zhu, Yuying and Liu, Lingbo and Liu, Yang and Li, Guanbin and Lin, Liang},
  booktitle={Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, {IJCAI-23}},
  year={2023}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: HORLN -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/HORLN.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Hybrid-Order Representation Learning for Electricity Theft Detection</h5>
                                <p class="pub-authors">Yuying Zhu, Yang Zhang, Lingbo Liu, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Mingzhi Mao, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Industrial Informatics (T-II), 2023</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/9785914" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/GillianZhu/HORLN" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibHORLN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/GillianZhu/HORLN?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/GillianZhu/HORLN?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/GillianZhu/HORLN?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibHORLN">
@article{zhu2022hybrid,
  title={Hybrid-Order Representation Learning for Electricity Theft Detection},
  author={Zhu, Yuying and Zhang, Yang and Liu, Lingbo and Liu, Yang and Li, Guanbin and Mao, Mingzhi and Lin, Liang},
  journal={IEEE Transactions on Industrial Informatics},
  year={2023}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: TFP -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/POI.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Urban Regional Function Guided Traffic Flow Prediction</h5>
                                <p class="pub-authors">Kuo Wang, Lingbo Liu, <b>Yang Liu</b><sup>✉</sup>, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Information Sciences (INS), 2023</p>
                                <div class="pub-links">
                                    <a href="https://www.sciencedirect.com/science/article/pii/S0020025523004334" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibTFP" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibTFP">
@article{TFP,
  title = {Urban regional function guided traffic flow prediction},
  journal = {Information Sciences},
  year = {2023},
  author = {Kuo Wang and LingBo Liu and Yang Liu and GuanBin Li and Fan Zhou and Liang Lin},
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DADA -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/DADA.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Dual adversarial adaptation for cross-device real-world image super-resolution</h5>
                                <p class="pub-authors">Xiaoqian Xu, Pengxu Wei, Weikai Chen, <b>Yang Liu</b>, Mingzhi Mao, Liang Lin, Guanbin Li</p>
                                <p class="pub-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022 <span class="badge badge-oral">Oral</span></p>
                                <div class="pub-links">
                                    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/lonelyhope/DADA" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibDADA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/lonelyhope/DADA?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/lonelyhope/DADA?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/lonelyhope/DADA?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibDADA">
@inproceedings{xu2022dual,
  title={Dual adversarial adaptation for cross-device real-world image super-resolution},
  author={Xu, Xiaoqian and Wei, Pengxu and Chen, Weikai and Liu, Yang and Mao, Mingzhi and Lin, Liang and Li, Guanbin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2022}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: MIR -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container ratio ratio-16x9">
                                <video muted="muted" autoplay loop playsinline src="img/MIR.mp4" style="object-fit: cover; width:100%; height:100%;"></video>
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Causal Reasoning Meets Visual Representation Learning: A Prospective Study</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Yushen Wei, Hong Yan, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">Machine Intelligence Research (MIR), 2022 <span class="badge badge-hot">Top-10 Downloads</span></p>
                                <div class="pub-links">
                                    <a href="https://link.springer.com/article/10.1007/s11633-022-1362-z" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://youtu.be/2lfNaTkcTHI" target="_blank"><i class="fab fa-youtube"></i> Video</a>
                                    <a href="https://mp.weixin.qq.com/s/-OlJ44DWE6nuX_OVyykURw" target="_blank"><i class="fab fa-weixin"></i> Interpretation</a>
                                    <a href="#bibMIR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/MIR?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/YangLiu9208/MIR?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/YangLiu9208/MIR?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibMIR">
@article{liu2022causal,
  title={Causal Reasoning Meets Visual Representation Learning: A Prospective Study},
  author={Liu, Yang and Wei, Yu-Shen and Yan, Hong and Li, Guan-Bin and Lin, Liang},
  journal={Machine Intelligence Research},
  year={2022}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: VSAR -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/VSAR.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-modal knowledge distillation for Vision-to-Sensor action recognition</h5>
                                <p class="pub-authors">Jianyuan Ni, Raunak Sarbajna, <b>Yang Liu</b>, Anne HH Ngu, Yan Yan</p>
                                <p class="pub-venue">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/9746752" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="#bibVSAR" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibVSAR">
@inproceedings{ni2022cross,
  title={Cross-modal knowledge distillation for vision-to-sensor action recognition},
  author={Ni, Jianyuan and Sarbajna, Raunak and Liu, Yang and Ngu, Anne HH and Yan, Yan},
  booktitle={ICASSP},
  year={2022}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: TCGL -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/TCGL.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">TCGL: Temporal Contrastive Graph for Self-supervised Video Representation Learning</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Keze Wang, Lingbo Liu, Haoyuan Lan, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2022 <span class="badge badge-hot">ESI Highly Cited & Hot</span></p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/9713748" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/YangLiu9208/TCGL/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibTCGL" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/TCGL?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/YangLiu9208/TCGL?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/YangLiu9208/TCGL?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibTCGL">
@article{liu2022tcgl,
  title={TCGL: Temporal Contrastive Graph for Self-Supervised Video Representation Learning},
  author={Liu, Yang and Wang, Keze and Liu, Lingbo and Lan, Haoyuan and Lin, Liang},
  journal={IEEE Transactions on Image Processing},
  year={2022}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: SAKDN -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/SAKDN.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Keze Wang, Guanbin Li, Liang Lin</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2021</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/9451581" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/YangLiu9208/SAKDN" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibSAKDN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/SAKDN?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/YangLiu9208/SAKDN?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/YangLiu9208/SAKDN?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibSAKDN">
@article{liu2021semantics,
  title={Semantics-aware adaptive knowledge distillation for sensor-to-vision action recognition},
  author={Liu, Yang and Wang, Keze and Li, Guanbin and Lin, Liang},
  journal={IEEE Transactions on Image Processing},
  year={2021}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: DIVAFN -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/TIP.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Zhaoyang Lu, Jing Li, Tao Yang, Chao Yao</p>
                                <p class="pub-venue">IEEE Transactions on Image Processing (T-IP), 2020</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/8931264" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://yangliu9208.github.io/DIVAFN/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibDIVAFN" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/DIVAFN?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/YangLiu9208/DIVAFN?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/YangLiu9208/DIVAFN?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibDIVAFN">
@article{liu2019deep,
  title={Deep image-to-video adaptation and fusion networks for action recognition},
  author={Liu, Yang and Lu, Zhaoyang and Li, Jing and Yang, Tao and Yao, Chao},
  journal={IEEE Transactions on Image Processing},
  year={2019}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Paper: JSRDA -->
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/TCSVT.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Hierarchically Learned View-Invariant Representations for Cross View Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Zhaoyang Lu, Jing Li, Tao Yang</p>
                                <p class="pub-venue">IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT), 2019</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/8453034" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://github.com/YangLiu9208/JSRDA/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibJSRDA" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/JSRDA?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/YangLiu9208/JSRDA?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/YangLiu9208/JSRDA?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibJSRDA">
@article{liu2018hierarchically,
  title={Hierarchically learned view-invariant representations for cross-view action recognition},
  author={Liu, Yang and Lu, Zhaoyang and Li, Jing and Yang, Tao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2018}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                 <!-- Paper: TSTDDs -->
                 <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4">
                            <div class="pub-img-container">
                                <img src="img/SPL.png" class="pub-img" alt="Paper Image">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Global Temporal Representation based CNNs for Infrared Action Recognition</h5>
                                <p class="pub-authors"><b>Yang Liu</b>, Zhaoyang Lu, Jing Li, Tao Yang, Chao Yao</p>
                                <p class="pub-venue">IEEE Signal Processing Letters (SPL), 2018</p>
                                <div class="pub-links">
                                    <a href="https://ieeexplore.ieee.org/document/8332532" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
                                    <a href="https://yangliu9208.github.io/TSTDDs/" target="_blank"><i class="fab fa-github"></i> Code</a>
                                    <a href="#bibTSTDDs" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="github-badges">
                                    <img alt="GitHub stars" src="https://img.shields.io/github/stars/YangLiu9208/TSTDDs?style=social">
                                    <img alt="GitHub forks" src="https://img.shields.io/github/forks/YangLiu9208/TSTDDs?style=social">
                                    <img alt="GitHub issues" src="https://img.shields.io/github/issues/YangLiu9208/TSTDDs?style=social">
                                </div>
                                <div class="collapse bibtex-box" id="bibTSTDDs">
@article{liu2018global,
  title={Global temporal representation based cnns for infrared action recognition},
  author={Liu, Yang and Lu, Zhaoyang and Li, Jing and Yang, Tao and Yao, Chao},
  journal={IEEE Signal Processing Letters},
  year={2018}
}</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- PhD Thesis -->
                <h3 class="mb-4 mt-5 text-muted" style="border-left: 5px solid #1e293b; padding-left: 15px;">PhD Dissertation</h3>
                <div class="pub-card card">
                    <div class="row g-0 align-items-center h-100">
                        <div class="col-md-4 text-center">
                            <div class="pub-img-container">
                                <img src="img/XD.gif" class="pub-img" alt="Thesis">
                            </div>
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <h5 class="pub-title">Cross-domain Human Action Recognition via Transfer Learning (基于迁移学习的跨域人体行为识别研究)</h5>
                                <p class="pub-authors"><b>Yang Liu</b> (Supervisor: Prof. Zhaoyang Lu)</p>
                                <p class="pub-venue">Xidian University, 2019</p>
                                <div class="pub-links">
                                    <a href="https://cdmd.cnki.com.cn/Article/CDMD-10701-1020000550.htm" target="_blank"><i class="fas fa-link"></i> Link</a>
                                    <a href="#bibPHD" data-bs-toggle="collapse"><i class="fas fa-quote-right"></i> BibTex</a>
                                </div>
                                <div class="collapse bibtex-box" id="bibPHD">
@phdthesis{刘阳2019基于迁移学习的跨域人体行为识别研究,
  title={基于迁移学习的跨域人体行为识别研究},
  author={刘阳},
  year={2019},
  school={西安电子科技大学}
}</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Activities Section -->
        <section class="resume-section bg-light" id="activities">
            <div class="resume-section-content">
                <h2 class="mb-5">Academic Services</h2>
                
                <div class="row g-4">
                    <div class="col-md-6">
                        <div class="service-card">
                            <h4 class="h5">Reviewer for Journals</h4>
                            <ul class="list-group list-group-flush">
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> IEEE Trans. on Image Processing (TIP)</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> IEEE Trans. on Neural Networks and Learning Systems (TNNLS)</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> IEEE Trans. on Cybernetics</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> International Journal of Computer Vision (IJCV)</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> ACM Trans. on Multimedia Computing Comm. and Applications</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> Pattern Recognition (PR)</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> Neural Networks</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> Information Fusion</li>
                                <li class="list-group-item bg-transparent"><i class="fas fa-check me-2 text-success"></i> Advanced Science</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="col-md-6">
                        <div class="service-card">
                            <h4 class="h5">PC Member / Reviewer for Conferences</h4>
                            <div class="d-flex flex-wrap gap-2 mb-3">
                                <span class="badge-conf">CVPR</span>
                                <span class="badge-conf">ICCV</span>
                                <span class="badge-conf">ECCV</span>
                                <span class="badge-conf">NeurIPS</span>
                                <span class="badge-conf">ICML</span>
                                <span class="badge-conf">ICLR</span>
                                <span class="badge-conf">AAAI</span>
                                <span class="badge-conf">IJCAI</span>
                                <span class="badge-conf">ACM MM</span>
                                <span class="badge-conf">ICASSP</span>
                                <span class="badge-conf">UbiComp</span>
                                <span class="badge-conf">ISWC</span>
                            </div>
                            <div class="alert alert-secondary small mb-0 border-0">
                                <i class="fas fa-info-circle me-1"></i> Serving as Program Committee member or Reviewer for top-tier computer vision and machine learning conferences.
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

    </div>

    <!-- Bootstrap 5 JS Bundle -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    
    <!-- Script to close navbar on mobile click -->
    <script>
        const navLinks = document.querySelectorAll('.js-scroll-trigger');
        const menuToggle = document.getElementById('navbarResponsive');
        const bsCollapse = new bootstrap.Collapse(menuToggle, {toggle:false});
        
        navLinks.forEach((l) => {
            l.addEventListener('click', () => {
                if (window.getComputedStyle(document.querySelector('.navbar-toggler')).display !== 'none') {
                    bsCollapse.hide();
                }
            });
        });
    </script>

</body>
</html>
